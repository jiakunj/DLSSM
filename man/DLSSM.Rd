% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DLSSM.R
\name{DLSSM}
\alias{DLSSM}
\title{Dynamic logistic state-space prediction model for binary outcomes}
\usage{
DLSSM(x, y, t, S, vary, autotune = TRUE, training_samp, Lambda = NULL, K)
}
\arguments{
\item{x}{n by q matrix of covariates}

\item{y}{A vector of binary outcome of length n}

\item{t}{A vector of observational timepoints of length n}

\item{S}{Number of batches (equally spaced)}

\item{vary}{A vector specify the covariates with time-varying coefficients. The remaining covariates have constant coefficients. For example, vector vary=(1,2) will specify first and third covariates as having time-varying coefficients. Intercept is always time-varying. If vary=NULL, only intercept is time-varying coefficient.}

\item{autotune}{T/F indicates whether or not the automatic tuning procedure described in Jiakun et al. (2021) should be applied.  Default is true.}

\item{training_samp}{Number of batches used as training data. If null (default), half number of batches will be used.}

\item{Lambda}{Specify smoothing parameters manually if autotune=F}

\item{K}{Specify how many steps ahead prediction of coefficients and probabilities}
}
\value{
A list with letters and numbers.
 \tabular{ll}{
   \code{Pred} \tab Predicted coefficients in the prediction step of Kalman Filter \cr
   \tab \cr
   \code{Pred.var} \tab Covariance matrix of Predicted coefficient in prediction step of Kalman Filter \cr
   \tab \cr
   \code{Filter} \tab Filtered coefficients in Kalman Filter \cr
   \tab \cr
   \code{Filter.var} \tab Covariance matrix of filtered coefficients in Kalman Filter \cr
   \tab \cr
   \code{Smooth} \tab Smoothing of coefficients \cr
   \tab \cr
   \code{Smooth.var} \tab Covariance matrix of smoothing of coefficients \cr
   \tab \cr
   \code{Pred.K} \tab K-steps ahead prediction of coefficients \cr
   \tab \cr
   \code{Pred.K.var} \tab Covariance matrix of K-steps ahead of prediction of coefficients \cr
   \tab \cr
   \code{Lambda} \tab Smoothing parameters \cr
   \tab \cr
   \code{q} \tab Number of covariates \cr
   \tab \cr
   \code{q1} \tab Number of covariates with varying coefficients \cr
   \tab \cr
   \code{train.time} \tab Time-points of training data \cr
   \tab \cr
   \code{dim} \tab Number of varying coefficients which equals to q+1(including a varying intercept) \cr
   \tab \cr
   \code{dim.con} \tab Number of constant coefficients \cr
   \tab \cr
   \code{TT} \tab Transformation matrix \cr
   \tab \cr
   \code{Q} \tab Variance matrix \cr
   \tab \cr
   \code{Prob.pred.K} \tab K-steps ahead prediction of probabilities \cr
   \tab \cr
   ...
 }
}
\description{
Implements dynamic logistic state-space prediction model for binary outcomes as described in Jiakun et al.(2021, Biometrics). In retrospective study,
it is suitable to use the main function DLSSM with specify trainning sample size. The results can also be repeated using subfunctions which is more suitable for online implementation. The algorithm was composed by training part and validation part.
On the stage of training, the smoothing parameters were selected by maximizing likelihood function. Then, based on the estimated smoothing parameters, run the Kalman filtering and
smoothing algorithm to estimate both the time-varying and time-invariant coefficients in the model. Based on the estimated coefficients and state-sapce model, it was straightforward to do prediction.
}
\details{
User first need to identify the covariates which have time-varying coefficients.
User need to decide the number of batches S which is achieved by dividing the observational time domain time into equally spaced time intervals. The number of batches S should satisfy a condition that all intervals have data.
The selection smoothing parameters usually be recommended by maximizing likelihood. The training data should have relatively large sample size to ensure the tuned smoothing parameters reliable.
}
\examples{
rm(list=ls())
set.seed(12345)
n=8000
beta0=function(t)   0.1*t-1   # Intercept
beta1=function(t)  cos(2*pi*t)   # Varying coefficient
beta2=function(t)  sin(2*pi*t)   # Varying coefficient
alph1=alph2=1
x=matrix(runif(n*4,min=-4,max=4),nrow=n,ncol=4)
t=sort(runif(n))
coef=cbind(beta0(t),beta1(t),beta2(t),rep(alph1,n),rep(alph2,n))
covar=cbind(rep(1,n),x)
linear=apply(coef*covar,1,sum)
prob=exp(linear)/(1+exp(linear))
y=as.numeric(runif(n)<prob)
fit=DLSSM(x,y,t,S=100,vary=c(1,2),autotune=TRUE,training_samp=75,K=1)

# plot one-step ahead predicted, filtered and smoothed cofficients
# DLSSM.plot(fit)
# fit$Lambda
# hist(fit$Prob.pred.K[[75]][[1]],main="Histogram of predicted
# probabilities of subjects in 76-th batch", xlab = "Probability")


# Implement the DLSSM in a "streaming" model
S=100
data.batched=Data.batched(x,y,t,S)
# Using DLSSM.init() on training dataset (first S.initial batches of data) to tune smoothing parameters
init.fit=DLSSM.init(data.batched,S.initial=75,vary=c(1,2),autotune=TRUE)
Prediction=matrix(NA,S,2*3+2)
Prediction.var=array(NA,dim=c(S,2*3+2,2*3+2))
Filtering=matrix(NA,S,2*3+2)
Filtering.var=array(NA,dim=c(S,2*3+2,2*3+2))
Prediction[1:75,]=init.fit$Pred
Prediction.var[1:75,,]=init.fit$Pred.var
Filtering[1:75,]=init.fit$Filter
Filtering.var[1:75,,]=init.fit$Filter.var

# The following streaming structure fit online dynamic implementation
for(i in 76:100){
  pred1=DLSSM.predict(init.fit,newx=NULL,K=1)
  Prediction[i,]=pred1$coef.pred
  Prediction.var[i,,]=pred1$coef.pred.var
  init.fit=DLSSM.filter(init.fit,data.batched$x.batch[[i]],data.batched$y.batch[[i]])
  Filtering[i,]=init.fit$Filter
  Filtering.var[i,,]=init.fit$Filter.var
}
# Smoothed results be generated by integrating historical prediction and filtering results
Smoothed=DLSSM.smooth(init.fit,Prediction,Prediction.var,Filtering,Filtering.var)
}
\author{
Jiakun Jiang, Wei Yang, Stephen E. Kimmel and Wensheng Guo
}
